\documentclass[paper=letter, fontsize=11pt]{scrartcl}

\usepackage{geometry}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[spanish, english]{babel}
\usepackage{hyperref}
\usepackage[backend=bibtex, style=trad-abbrv]{biblatex}
\usepackage{sectsty}

\addbibresource{bibliography.bib}

\geometry{
  top=1in,
  right=1in,
  left=1in,
  bottom=1in
}

\allsectionsfont{\raggedright\large \textit\normalfont\scshape\emph}

\title{
  \normalsize
  Latinx in AI Coalition at NIPS 2018
}

\subtitle{\normalsize Abstract Submission}

\author{\normalsize Albert Manuel Orozco Camacho
        \footnote{Facultad de Ciencias,
        Universidad Nacional Autónoma de México (\emph{UNAM})}}

\date{\normalsize \today}

\begin{document}

\maketitle

\section*{Title}

\noindent
\emph{\textbf{Challenges in Automatic Meme Generation Using Deep Neural Networks}}

\section*{Abstract}

\noindent
Today's Internet is full of \textbf{memes}: small chunks of data which represent a large proportion\
of a social network's communication ``protocol''. As coined by Dawkins in his 1976 book\
\emph{``The Selfish Gene''} \cite{dawkins2006}, the meme is the fundamental building-block of information whose behavior seems very likely to that of a gene (\emph{better} memes tend to prevail longer in the Internet).\
Also, there is an evolution mechanism that allows older memes to adapt to current trends.\par
In this project, the problem of learning representations from a meme dataset and immediately generating new\
data is studied, as a basis to motivate the further study of memes using \emph{state-of-the-art} machine\
learning methods. In particular, we develop a deep neural architecture which attempts to learn a language\
model out of a dataset of plain meme images along with several associated captions.\par
Much of deep learning's success is justified by the outstanding performance of Vinyals', \textit{et al},\
\textbf{Show-and-Tell model} \cite{DBLP:journals/corr/VinyalsTBE14}. We report experiments directly\
using such model, in comparison with a proposed model that uses a \emph{more shallow} convolutional network.

\begin{figure}[h]
    \centering
    \begin{minipage}[l]{0.2\linewidth}
    \includegraphics[width=\linewidth]{img/meme2.jpg}
    \end{minipage}\hfill
    \begin{minipage}[r]{0.2\linewidth}
    \includegraphics[width=\linewidth]{img/meme3.jpg}
    \end{minipage}\hfill
    \begin{minipage}[r]{0.2\linewidth}
    \includegraphics[width=\linewidth]{img/meme4.jpg}
    \end{minipage}\hfill
    \begin{minipage}[r]{0.2\linewidth}
    \includegraphics[width=\linewidth]{img/meme6.jpg}
    \end{minipage}
	\caption{
        Meme examples. Most of them were 
        popular between 2009 and 2013, yet some of them have evolved!
        (Image taken from \url{https://memegenerator.net}.)
    }
    \label{fig1}
\end{figure}
As pointed out by Figure \ref{fig1}, we choose to start with memes that mainly consist on an\
image centered on a main character and a caption. We, finally, report some evaluation measurements\
to analyze our architecture's performance.\par
This project is meant to be presented as an undergraduate thesis, under the supervision of\
\href{http://turing.iimas.unam.mx/~ivanvladimir/}{Dr Ivan Vladimir Meza Ruiz}.


%% \nocite{*}
\printbibliography[title={Bibliography}]

\end{document}
